{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TSKsteff/Classificacao_De_Imagens/blob/main/CNN_Parte_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSPCom-KmApV"
      },
      "source": [
        "# Convolutional Neural Network (CNN)\n",
        "\n",
        "Exemplo retirado do site da Tensorflow e Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLGkt5qiyz4E"
      },
      "source": [
        "Este tutorial demonstra o treinamento de uma [Rede Neural Convolucional](https://developers.google.com/machine-learning/glossary/#convolutional_neural_network) (CNN) simples para classificar [imagens CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html). Como este tutorial usa a [API Sequencial Keras](https://www.tensorflow.org/guide/keras/overview), criar e treinar seu modelo levará apenas algumas linhas de código.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7KBpffWzlxH"
      },
      "source": [
        "### Import TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRFxccghyMVo"
      },
      "source": [
        "### Baixe e prepare o conjunto de dados CIFAR10\n",
        "\n",
        "\n",
        "O conjunto de dados CIFAR10 contém 60.000 imagens coloridas em 10 classes, com 6.000 imagens em cada classe. O conjunto de dados é dividido em 50.000 imagens de treinamento e 10.000 imagens de teste. As classes são mutuamente exclusivas e não há sobreposição entre elas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME_DIR = os.getcwd()\n",
        "print(HOME_DIR)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)\n",
        "\n",
        "HOME_DIR = '/content/gdrive/MyDrive/Colab Notebooks'\n",
        "os.chdir(os.path.join(HOME_DIR, \"dataset\"))\n",
        "\n",
        "!pwd\n",
        "dataset_dir = '/content/gdrive/MyDrive/Colab Notebooks/dataset'\n",
        "\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "test_dir = os.path.join(dataset_dir, 'test')"
      ],
      "metadata": {
        "id": "6R-6DNOOjl3V",
        "outputId": "04c19f38-be06-4231-b196-d4b83aa2a271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Colab Notebooks/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_processed_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label in ['Positive', 'Negative']:\n",
        "        label_dir = os.path.join(data_dir, label)\n",
        "        for filename in os.listdir(label_dir):\n",
        "            if filename.endswith('.jpg'):\n",
        "                img = cv2.imread(os.path.join(label_dir, filename))\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Carregar dados processados\n",
        "train_image_processed, train_labels_processed = load_processed_data(train_dir)\n",
        "test_image_processed, test_labels_processed = load_processed_data()\n",
        "\n",
        "print(\"Train:\", train_image_processed.shape, train_labels_processed.shape)\n",
        "print(\"Test:\", test_image_processed.shape, test_labels_processed.shape)"
      ],
      "metadata": {
        "id": "xEXhLMSjGSbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(5):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(cv2.cvtColor(train_image_processed[i], cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Original: {train_labels_processed[i]}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 5, i+6)\n",
        "    plt.imshow(cv2.cvtColor(test_image_processed[i], cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Processed: {test_labels_processed[i]}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pH6LUq9OGh_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wArwCTJJlUa"
      },
      "source": [
        "### Verifique os dados\n",
        "\n",
        "Para verificar se o conjunto de dados está correto, vamos traçar as primeiras 25 imagens do conjunto de treinamento e exibir o nome da classe abaixo de cada imagem:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3PAELE2eSU9"
      },
      "outputs": [],
      "source": [
        "class_names = ['Positive', 'Negative']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_image_processed[i])\n",
        "    plt.xlabel(class_names[train_labels_processed[i][0]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oewp-wYg31t9"
      },
      "source": [
        "### Crie a base convolucional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQvqXpNyN3x"
      },
      "source": [
        "As 6 linhas de código abaixo definem a base convolucional usando um padrão comum: uma pilha de [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) e [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) camadas.\n",
        "\n",
        "Como entrada, uma CNN recebe tensores de forma (image_height, image_width, color_channels), ignorando o tamanho do lote. Se você é novo nessas dimensões, color_channels refere-se a (R,G,B). Neste exemplo, você configurará sua CNN para processar entradas de formato (32, 32, 3), que é o formato das imagens CIFAR. Você pode fazer isso passando o argumento `input_shape` para sua primeira camada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9YmGQBQPrdn"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvDVFkg-2DPm"
      },
      "source": [
        "Vamos exibir a arquitetura do seu modelo até agora:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-C4XBg4UTJy"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j-AXYeZ2GO5"
      },
      "source": [
        "Acima, você pode ver que a saída de cada camada Conv2D e MaxPooling2D é um tensor 3D de forma (altura, largura, canais). As dimensões de largura e altura tendem a encolher à medida que você se aprofunda na rede. O número de canais de saída para cada camada Conv2D é controlado pelo primeiro argumento (por exemplo, 32 ou 64). Normalmente, à medida que a largura e a altura diminuem, você pode permitir (computacionalmente) adicionar mais canais de saída em cada camada Conv2D."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v8sVOtG37bT"
      },
      "source": [
        "### Adicione camadas densas no topo\n",
        "\n",
        "Para completar o modelo, você alimentará o último tensor de saída da base convolucional (da forma (4, 4, 64)) em uma ou mais camadas densas para realizar a classificação. As camadas densas recebem vetores como entrada (que são 1D), enquanto a saída atual é um tensor 3D. Primeiro, você achatará (ou desenrolará) a saída 3D para 1D e, em seguida, adicionará uma ou mais camadas densas no topo. CIFAR tem 10 classes de saída, então você usa uma camada densa final com 10 saídas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRs95d6LUVEi"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipGiQMcR4Gtq"
      },
      "source": [
        "Aqui está a arquitetura completa do seu modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yu_m-TZUWGX"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNKXi-Gy3RO-"
      },
      "source": [
        "O resumo da rede mostra que (4, 4, 64) as saídas foram achatadas em vetores de forma (1024) antes de passar por duas camadas densas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3odqfHP4M67"
      },
      "source": [
        "### Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdDzI75PUXrG"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_image_processed, train_labels_processed, epochs=10,\n",
        "                    validation_data=(test_image_processed, test_labels_processed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKgyC5K_4O0d"
      },
      "source": [
        "### Avalie o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtyDF0MKUcM7"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_image_processed,  test_labels_processed, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LvwaKhtUdOo"
      },
      "outputs": [],
      "source": [
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfJ8AR03gT5"
      },
      "source": [
        "Sua CNN simples alcançou uma precisão de teste de mais de 70%. Nada mal para algumas linhas de código! Para outro estilo de CNN, confira o exemplo de [início rápido do TensorFlow 2 para especialistas](https://www.tensorflow.org/tutorials/quickstart/advanced) que usa a API de subclasse Keras e `tf.GradientTape`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testa o modelo imagem por imagem"
      ],
      "metadata": {
        "id": "-kz3Ju3XxW0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "num_image = 1\n",
        "plt.imshow(test_image_processed[num_image])\n",
        "plt.xlabel(class_names[test_labels_processed[num_image][0]])\n",
        "plt.show()\n",
        "image2test = test_image_processed[num_image]\n",
        "image2test = image2test.reshape((-1,32,32,3))\n",
        "print(model.predict(image2test))\n",
        "#['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "#     0            1           2      3       4     5       6        7       8       9"
      ],
      "metadata": {
        "id": "s9VSfzscxVkK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}